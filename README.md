# EEE 443 Neural Networks Image Captioning Project
**Brief summary of the project:**
In  this  work,  we  experimented  with  various  image  captioning  architectures  for  encoding  images and decoding their captions, including a simple CNN and RNN model, a model with attention,  and a fully convolutional  model. We train and test our models on the provided COCO2014 dataset, discussing in detail both the image and caption pre-processing needed. We then discuss our successes and shortcomings and compare our results with those in the literature. We were able to observe that the image captioning model with attention not only provided the best results out of all the other tested models, but it also outperformed the paper that it is based on.

Our trained models are included in the following link:
https://drive.google.com/drive/folders/1EfcqQ0tsOArqxL-o3aStwtm56IaAy0CP
